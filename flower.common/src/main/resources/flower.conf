akka.actor {
  serializers {
    # Define kryo serializer
    kryo = "com.romix.akka.serialization.kryo.KryoSerializer"
    hessian = "com.ly.train.flower.common.akka.serializer.hessian.HessianSerializer"
  }

  extensions = ["com.romix.akka.serialization.kryo.KryoSerializationExtension$", "com.ly.train.flower.common.akka.serializer.hessian.HessianSerializationExtension"]

  kryo {
    # Possibles values for type are: graph or nograph
    # graph supports serialization of object graphs with shared nodes
    # and cyclic references, but this comes at the expense of a small
    # overhead nograph does not support object grpahs with shared nodes,
    # but is usually faster
    type = "graph"

    # Possible values for idstrategy are:
    # default, explicit, incremental, automatic
    #
    # default - slowest and produces bigger serialized representation.
    # Contains fully-qualified class names (FQCNs) for each class. Note
    # that selecting this strategy does not work in version 0.3.2, but
    # is available from 0.3.3 onward.
    #
    # explicit - fast and produces compact serialized representation.
    # Requires that all classes that will be serialized are pre-registered
    # using the "mappings" and "classes" sections. To guarantee that both
    # sender and receiver use the same numeric ids for the same classes it
    # is advised to provide exactly the same entries in the "mappings"
    # section.
    #
    # incremental - fast and produces compact serialized representation.
    # Support optional pre-registering of classes using the "mappings"
    # and "classes" sections. If class is not pre-registered, it will be
    # registered dynamically by picking a next available id To guarantee
    # that both sender and receiver use the same numeric ids for the same
    # classes it is advised to pre-register them using at least the "classes" section.
    #
    # automatic -  use the pre-registered classes with fallback to FQCNs
    # Contains fully-qualified class names (FQCNs) for each non pre-registered
    # class in the "mappings" and "classes" sections. This strategy was
    # added in version 0.4.1 and will not work with the previous versions
    idstrategy = "automatic"

    # Define a default queue builder, by default ConcurrentLinkedQueue is used.
    # Create your own queue builder by implementing the trait QueueBuilder,
    # useful for paranoid GC users that want to use JCtools MpmcArrayQueue for example.
    #
    # If you pass a bounded queue make sure its capacity is equal or greater than the
    # maximum concurrent remote dispatcher threads your application will ever have
    # running; failing to do this will have a negative performance impact:
    #
    # custom-queue-builder = "a.b.c.KryoQueueBuilder"

    # Define a default size for byte buffers used during serialization
    buffer-size = 4096

    # The serialization byte buffers are doubled as needed until they
    # exceed max-buffer-size and an exception is thrown. Can be -1
    # for no maximum.
    max-buffer-size = -1

    # If set, akka uses manifests to put a class name
    # of the top-level object into each message
    use-manifests = false

    # If set it will use the UnsafeInput and UnsafeOutput
    # Kyro IO instances. Please note that there is no guarantee
    # for backward/forward compatibility of unsafe serialization.
    # It is also not compatible with the safe-serialized values.
    # The unsafe IO usually creates bugger payloads but is faster
    # for some types, e.g. native arrays.
    use-unsafe = false

    # The transformations that have be done while serialization
    # Supported transformations: compression and encryption
    # accepted values(comma separated if multiple): off | lz4 | deflate | aes
    # Transformations occur in the order they are specified
    # post-serialization-transformations = "lz4,aes"

    # Settings for aes encryption, if included in transformations AES
    # algo mode, key and custom key class can be specified AES algo mode
    # defaults to 'AES/CBC/PKCS5Padding' and key to 'ThisIsASecretKey'.
    # If custom key class is provided, Kryo will use the class specified
    # by a fully qualified class name to get custom AES key. Such a
    # class should define the method 'kryoAESKey'. This key overrides 'key'.
    # If class doesn't contain 'kryoAESKey' method, specified key is used.
    # If this is not present, default key is used


    # Log implicitly registered classes. Useful, if you want to know all
    # classes which are serialized. You can then use this information in
    # the mappings and/or classes sections
    implicit-registration-logging = false

    # If enabled, Kryo logs a lot of information about serialization process.
    # Useful for debugging and lowl-level tweaking
    kryo-trace = false

    # If proviced, Kryo uses the class specified by a fully qualified
    # class name to perform a custom initialization of Kryo instances in
    # addition to what is done automatically based on the config file.
    #kryo-custom-serializer-init = "com.ly.train.flower.KryoInit"

    # If enabled, allows Kryo to resolve subclasses of registered Types.
    #
    # This is primarily useful when idstrategy is set to "explicit". In this
    # case, all classes to be serialized must be explicitly registered. The
    # problem is that a large number of common Scala and Akka types (such as
    # Map and ActorRef) are actually traits that mask a large number of
    # specialized classes that deal with various situations and optimizations.
    # It isn't straightforward to register all of these, so you can instead
    # register a single supertype, with a serializer that can handle *all* of
    # the subclasses, and the subclasses get serialized with that.
    #
    # Use this with care: you should only rely on this when you are confident
    # that the superclass serializer covers all of the special cases properly.
    resolve-subclasses = false
  }
  # kryo end
}


dispatcher {
  # Must be one of the following
  # Dispatcher, PinnedDispatcher, or a FQCN to a class inheriting
  # MessageDispatcherConfigurator with a public constructor with
  # both com.typesafe.config.Config parameter and
  # akka.dispatch.DispatcherPrerequisites parameters.
  # PinnedDispatcher must be used together with executor=thread-pool-executor.
  type = "Dispatcher"

  # Which kind of ExecutorService to use for this dispatcher
  # Valid options:
  #  - "default-executor" requires a "default-executor" section
  #  - "fork-join-executor" requires a "fork-join-executor" section
  #  - "thread-pool-executor" requires a "thread-pool-executor" section
  #  - "affinity-pool-executor" requires an "affinity-pool-executor" section
  #  - A FQCN of a class extending ExecutorServiceConfigurator
  executor = "default-executor"

  # This will be used if you have set "executor = "default-executor"".
  # If an ActorSystem is created with a given ExecutionContext, this
  # ExecutionContext will be used as the default executor for all
  # dispatchers in the ActorSystem configured with
  # executor = "default-executor". Note that "default-executor"
  # is the default value for executor, and therefore used if not
  # specified otherwise. If no ExecutionContext is given,
  # the executor configured in "fallback" will be used.
  default-executor {
    fallback = "fork-join-executor"
  }

  # This will be used if you have set "executor = "affinity-pool-executor""
  # Underlying thread pool implementation is akka.dispatch.affinity.AffinityPool.
  # This executor is classified as "ApiMayChange".
  affinity-pool-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4

    # The parallelism factor is used to determine thread pool size using the
    # following formula: ceil(available processors * factor). Resulting size
    # is then bounded by the parallelism-min and parallelism-max values.
    parallelism-factor = 0.8

    # Max number of threads to cap factor-based parallelism number to.
    parallelism-max = 64

    # Each worker in the pool uses a separate bounded MPSC queue. This value
    # indicates the upper bound of the queue. Whenever an attempt to enqueue
    # a task is made and the queue does not have capacity to accommodate
    # the task, the rejection handler created by the rejection handler specified
    # in "rejection-handler" is invoked.
    task-queue-size = 512

    # FQCN of the Rejection handler used in the pool.
    # Must have an empty public constructor and must
    # implement akka.actor.affinity.RejectionHandlerFactory.
    rejection-handler = "akka.dispatch.affinity.ThrowOnOverflowRejectionHandler"

    # Level of CPU time used, on a scale between 1 and 10, during backoff/idle.
    # The tradeoff is that to have low latency more CPU time must be used to be
    # able to react quickly on incoming messages or send as fast as possible after
    # backoff backpressure.
    # Level 1 strongly prefer low CPU consumption over low latency.
    # Level 10 strongly prefer low latency over low CPU consumption.
    idle-cpu-level = 5

    # FQCN of the akka.dispatch.affinity.QueueSelectorFactory.
    # The Class of the FQCN must have a public constructor with a
    # (com.typesafe.config.Config) parameter.
    # A QueueSelectorFactory create instances of akka.dispatch.affinity.QueueSelector,
    # that is responsible for determining which task queue a Runnable should be enqueued in.
    queue-selector = "akka.dispatch.affinity.FairDistributionHashCache"

    # When using the "akka.dispatch.affinity.FairDistributionHashCache" queue selector
    # internally the AffinityPool uses two methods to determine which task
    # queue to allocate a Runnable to:
    # - map based - maintains a round robin counter and a map of Runnable
    # hashcodes to queues that they have been associated with. This ensures
    # maximum fairness in terms of work distribution, meaning that each worker
    # will get approximately equal amount of mailboxes to execute. This is suitable
    # in cases where we have a small number of actors that will be scheduled on
    # the pool and we want to ensure the maximum possible utilization of the
    # available threads.
    # - hash based - the task - queue in which the runnable should go is determined
    # by using an uniformly distributed int to int hash function which uses the
    # hash code of the Runnable as an input. This is preferred in situations where we
    # have enough number of distinct actors to ensure statistically uniform
    # distribution of work across threads or we are ready to sacrifice the
    # former for the added benefit of avoiding map look-ups.
    fair-work-distribution {
      # The value serves as a threshold which determines the point at which the
      # pool switches from the first to the second work distribution schemes.
      # For example, if the value is set to 128, the pool can observe up to
      # 128 unique actors and schedule their mailboxes using the map based
      # approach. Once this number is reached the pool switches to hash based
      # task distribution mode. If the value is set to 0, the map based
      # work distribution approach is disabled and only the hash based is
      # used irrespective of the number of unique actors. Valid range is
      # 0 to 2048 (inclusive)
      threshold = 128
    }
  }

  # This will be used if you have set "executor = "fork-join-executor""
  # Underlying thread pool implementation is akka.dispatch.forkjoin.ForkJoinPool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 8

    # The parallelism factor is used to determine thread pool size using the
    # following formula: ceil(available processors * factor). Resulting size
    # is then bounded by the parallelism-min and parallelism-max values.
    parallelism-factor = 16

    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 128

    # Setting to "FIFO" to use queue like peeking mode which "poll" or "LIFO" to use stack
    # like peeking mode which "pop".
    task-peeking-mode = "FIFO"
  }

  # This will be used if you have set "executor = "thread-pool-executor""
  # Underlying thread pool implementation is java.util.concurrent.ThreadPoolExecutor
  thread-pool-executor {
    # Keep alive time for threads
    keep-alive-time = 60s

    # Define a fixed thread pool size with this property. The corePoolSize
    # and the maximumPoolSize of the ThreadPoolExecutor will be set to this
    # value, if it is defined. Then the other pool-size properties will not
    # be used.
    #
    # Valid values are: `off` or a positive integer.
    fixed-pool-size = off

    # Min number of threads to cap factor-based corePoolSize number to
    core-pool-size-min = 8

    # The core-pool-size-factor is used to determine corePoolSize of the
    # ThreadPoolExecutor using the following formula:
    # ceil(available processors * factor).
    # Resulting size is then bounded by the core-pool-size-min and
    # core-pool-size-max values.
    core-pool-size-factor = 3.0

    # Max number of threads to cap factor-based corePoolSize number to
    core-pool-size-max = 64

    # Minimum number of threads to cap factor-based maximumPoolSize number to
    max-pool-size-min = 8

    # The max-pool-size-factor is used to determine maximumPoolSize of the
    # ThreadPoolExecutor using the following formula:
    # ceil(available processors * factor)
    # The maximumPoolSize will not be less than corePoolSize.
    # It is only used if using a bounded task queue.
    max-pool-size-factor = 3.0

    # Max number of threads to cap factor-based maximumPoolSize number to
    max-pool-size-max = 64

    # Specifies the bounded capacity of the task queue (< 1 == unbounded)
    task-queue-size = -1

    # Specifies which type of task queue will be used, can be "array" or
    # "linked" (default)
    task-queue-type = "linked"

    # Allow core threads to time out
    allow-core-timeout = on
  }

  # How long time the dispatcher will wait for new actors until it shuts down
  shutdown-timeout = 1s

  # Throughput defines the number of messages that are processed in a batch
  # before the thread is returned to the pool. Set to 1 for as fair as possible.
  throughput = 5

  # Throughput deadline for Dispatcher, set to 0 or negative for no deadline
  throughput-deadline-time = 0ms

  # For BalancingDispatcher: If the balancing dispatcher should attempt to
  # schedule idle actors using the same dispatcher when a message comes in,
  # and the dispatchers ExecutorService is not fully busy already.
  attempt-teamwork = on

  # If this dispatcher requires a specific type of mailbox, specify the
  # fully-qualified class name here; the actually created mailbox will
  # be a subtype of this type. The empty string signifies no requirement.
  mailbox-requirement = ""
}

